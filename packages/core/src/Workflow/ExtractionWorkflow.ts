/**
 * ExtractionWorkflow - Orchestration layer for knowledge extraction
 *
 * Provides two workflow functions:
 * 1. startExtractionWorkflow - Start a new extraction run from scratch
 * 2. resumeExtractionWorkflow - Resume an interrupted run from last checkpoint
 *
 * Features:
 * - Sequential batch processing with checkpointing
 * - Entity cache accumulation across batches
 * - Optimistic locking for status updates
 * - Error handling with status updates
 * - Resume capability from any checkpoint
 *
 * Architecture:
 * - Plain Effect.gen (NOT @effect/workflow)
 * - Manual checkpointing using Activities
 * - Coordinates all infrastructure (RunService, Activities, etc.)
 */

import { Effect, type Graph, HashMap } from "effect"
import type { NodeId, OntologyContext } from "../Graph/Types.js"
import type { EntityRef } from "../Prompt/EntityCache.js"
import { RunService } from "../Services/RunService.js"
import type { CreateRunParams, ResumeRunParams } from "../Services/WorkflowTypes.js"
import {
  findLastCheckpointActivity,
  loadCheckpointActivity,
  loadInputTextActivity,
  mergeAllBatchesActivity,
  processBatchActivity,
  saveBatchWithCheckpointActivity,
  saveFinalArtifactActivity
} from "./Activities.js"
import { CheckpointCoordinatorService } from "./CheckpointCoordination.js"

// ============================================================================
// Utility Functions
// ============================================================================

/**
 * Chunk array into batches
 */
const chunk = <T>(array: Array<T>, size: number): Array<Array<T>> => {
  const result: Array<Array<T>> = []
  for (let i = 0; i < array.length; i += size) {
    result.push(array.slice(i, i + size))
  }
  return result
}

/**
 * Simple sliding window text chunking
 *
 * Splits text into chunks of approximately `windowSize` characters
 * with `overlap` characters of overlap between adjacent chunks.
 *
 * This is a simple character-based implementation.
 * For production, consider using NlpService.streamChunks for sentence-aware chunking.
 */
export const chunkText = (
  text: string,
  windowSize: number,
  overlap: number
): ReadonlyArray<string> => {
  if (text.length === 0) return []
  if (windowSize <= 0) throw new Error("windowSize must be positive")
  if (overlap < 0) throw new Error("overlap cannot be negative")
  if (overlap >= windowSize) throw new Error("overlap must be less than windowSize")

  const chunks: Array<string> = []
  const step = windowSize - overlap

  for (let i = 0; i < text.length; i += step) {
    const end = Math.min(i + windowSize, text.length)
    chunks.push(text.slice(i, end))

    if (end === text.length) break
  }

  return chunks
}

// ============================================================================
// Extended Workflow Parameter Types
// ============================================================================

/**
 * Extended parameters for starting a new extraction workflow
 *
 * Extends CreateRunParams with workflow-specific configuration:
 * - ontologyGraph: Graph representation of ontology for prompt generation
 * - windowSize: Character window size for text chunking
 * - overlap: Character overlap between chunks
 * - batchSize: Number of chunks to process per batch
 * - runId: Optional pre-generated runId (if not provided, will be generated by RunService)
 */
export interface StartWorkflowParams extends CreateRunParams {
  readonly ontologyGraph: Graph.Graph<NodeId, unknown>
  readonly windowSize: number
  readonly overlap: number
  readonly batchSize: number
  readonly runId?: string // Optional: if provided, use this instead of generating
}

/**
 * Extended parameters for resuming an extraction workflow
 *
 * Extends ResumeRunParams with workflow-specific configuration:
 * - ontology: OntologyContext needed for processing remaining batches
 * - ontologyGraph: Graph representation of ontology
 */
export interface ResumeWorkflowParams extends ResumeRunParams {
  readonly ontology: OntologyContext
  readonly ontologyGraph: Graph.Graph<NodeId, unknown>
}

/**
 * Workflow result type
 */
export interface WorkflowResult {
  readonly runId: string
  readonly status: "completed" | "failed"
  readonly error?: string
}

// ============================================================================
// Workflow: Start Extraction
// ============================================================================

/**
 * Start a new extraction workflow from scratch
 *
 * Sequence:
 * 1. Create run record (RunService.create)
 * 2. Load input text (loadInputTextActivity)
 * 3. Chunk text into sliding windows
 * 4. Batch chunks for processing
 * 5. Update run with total batch count
 * 6. Process each batch sequentially with checkpointing
 * 7. Merge all batch outputs (mergeAllBatchesActivity)
 * 8. Save final artifact (saveFinalArtifactActivity)
 * 9. Mark run complete (RunService.markComplete)
 *
 * Error handling:
 * - Catches all errors and marks run as failed
 * - Uses optimistic locking for status updates
 * - Returns structured result with error details
 */
export const startExtractionWorkflow = (params: StartWorkflowParams) =>
  Effect.gen(function*() {
    const runService = yield* RunService

    // 1. Create run record (use provided runId if available)
    const createParams: CreateRunParams = {
      inputText: params.inputText,
      ontology: params.ontology,
      llmProvider: params.llmProvider,
      model: params.model
    }
    const { ontologyHash, runId } = yield* runService.create(
      createParams,
      params.runId
    )

    // Store chunking parameters for resume capability
    yield* runService.updateChunkingParams(
      runId,
      params.windowSize,
      params.overlap,
      params.batchSize
    )

    // Track status version for optimistic locking
    let statusVersion = 0

    // 2. Load input text (verifies it was saved correctly)
    const inputText = yield* loadInputTextActivity({ runId })

    // 3. Chunk text using sliding window
    const chunks = chunkText(inputText, params.windowSize, params.overlap)

    // 4. Batch chunks for processing
    const batches = chunk(Array.from(chunks), params.batchSize)

    // 5. Update run with total batch count
    yield* runService.updateProgress(runId, 0, batches.length)

    // 6. Update status to running
    yield* runService.updateStatus(runId, "running", statusVersion)
    statusVersion++

    // Handle zero-batch runs (empty input or all filtered)
    if (batches.length === 0) {
      // No batches to process - mark as completed immediately
      yield* saveFinalArtifactActivity({
        runId,
        mergedTurtle: "" // Empty output for zero-batch runs
      })
      return { runId, status: "completed" as const }
    }

    // 7. Process batches sequentially with checkpointing
    let entityCache = HashMap.empty<string, EntityRef>()
    const coordinator = yield* CheckpointCoordinatorService

    for (const [batchIndex, batchChunks] of batches.entries()) {
      // Create checkpoint token for coordination
      const checkpointToken = yield* coordinator.createCheckpoint(runId, batchIndex)

      // Process batch with current entity cache
      const result = yield* processBatchActivity({
        runId,
        chunks: batchChunks,
        batchIndex,
        ontology: params.ontology,
        ontologyGraph: params.ontologyGraph,
        ontologyHash,
        initialEntitySnapshot: batchIndex === 0 ? undefined : entityCache
      })

      // Save batch + checkpoint atomically
      const _saveResult = yield* saveBatchWithCheckpointActivity({
        runId,
        batchIndex,
        turtleRdf: result.rdf,
        entityCache: result.entities
      }).pipe(
        // Complete checkpoint on success
        Effect.tap((paths) =>
          coordinator.completeCheckpoint(checkpointToken, {
            batchPath: paths.batchResult.path,
            checkpointPath: paths.checkpointResult.path,
            batchHash: paths.batchResult.hexHash,
            checkpointHash: paths.checkpointResult.hexHash
          })
        ),
        // Fail checkpoint on error
        Effect.tapError((error) => coordinator.failCheckpoint(checkpointToken, error))
      )

      // Wait for checkpoint completion before proceeding
      yield* coordinator.awaitCheckpoint(checkpointToken)

      // Update entity cache for next batch
      entityCache = result.entities

      // Update progress ONLY after checkpoint confirmed
      yield* runService.updateProgress(runId, batchIndex + 1, batches.length)
    }

    // 8. Merge all batches
    const mergedRdf = yield* mergeAllBatchesActivity({ runId })

    // 9. Save final artifact (this also marks run complete)
    yield* saveFinalArtifactActivity({ runId, mergedTurtle: mergedRdf })

    return { runId, status: "completed" as const }
  }).pipe(
    Effect.catchAll((error) =>
      // Handle ALL errors - mark run as failed
      Effect.gen(function*() {
        const runService = yield* RunService

        // Try to extract runId from error context if available
        // If run creation failed, we won't have a runId yet
        const runId = "runId" in error ? String((error as any).runId) : "unknown"

        if (runId !== "unknown") {
          yield* runService.markFailed(runId, String(error))
        }

        return {
          runId,
          status: "failed" as const,
          error: String(error)
        }
      })
    )
  )

// ============================================================================
// Workflow: Resume Extraction
// ============================================================================

/**
 * Resume an interrupted extraction workflow from last checkpoint
 *
 * Sequence:
 * 1. Load run metadata (RunService.getById)
 * 2. Verify run status (cannot resume completed/failed runs)
 * 3. Find last checkpoint (findLastCheckpointActivity)
 * 4. Restore entity cache from checkpoint (loadCheckpointActivity)
 * 5. Load input text and re-chunk (to determine total batches)
 * 6. Resume batch processing from next batch
 * 7. Same merge/save/complete logic as startExtractionWorkflow
 *
 * Special cases:
 * - If run is already completed, return immediately
 * - If run is failed, fail with error
 * - If no checkpoints exist, start from batch 0
 *
 * Error handling:
 * - Same as startExtractionWorkflow
 * - Updates status to failed on errors
 */
export const resumeExtractionWorkflow = (params: ResumeWorkflowParams) =>
  Effect.gen(function*() {
    const runService = yield* RunService

    // 1. Load run metadata
    const runOption = yield* runService.getById(params.runId)

    if (runOption._tag === "None") {
      return yield* Effect.fail(new Error(`Run ${params.runId} not found`))
    }

    const run = runOption.value

    // 2. Check run status
    if (run.status === "completed") {
      // Already completed - return immediately
      return { runId: params.runId, status: "completed" as const }
    }

    if (run.status === "failed") {
      return yield* Effect.fail(
        new Error(`Cannot resume failed run ${params.runId}`)
      )
    }

    // Track status version for optimistic locking
    let statusVersion = run.status_version

    // 3. Find last checkpoint
    const lastCheckpoint = yield* findLastCheckpointActivity({
      runId: params.runId
    })

    // 4. Restore entity cache from checkpoint (if exists)
    let entityCache = HashMap.empty<string, EntityRef>()
    let startBatchIndex = 0

    if (lastCheckpoint !== null) {
      entityCache = yield* loadCheckpointActivity({
        runId: params.runId,
        batchIndex: lastCheckpoint.batch_index
      })
      startBatchIndex = lastCheckpoint.batch_index + 1
    }

    // 5. Load input text and re-chunk to determine batches
    const inputText = yield* loadInputTextActivity({ runId: params.runId })

    // Read chunking params from run record (stored during run creation)
    const windowSize = run.window_size ?? 1000 // Fallback to defaults for backward compatibility
    const overlap = run.overlap ?? 200
    const batchSize = run.batch_size ?? 10

    if (run.window_size === null || run.overlap === null || run.batch_size === null) {
      yield* Effect.logWarning(
        `Run ${params.runId} missing chunking params, using defaults. This may cause incorrect resume behavior.`
      )
    }

    const chunks = chunkText(inputText, windowSize, overlap)
    const batches = chunk(Array.from(chunks), batchSize)

    // 6. Update status to running if not already
    if (run.status !== "running") {
      yield* runService.updateStatus(params.runId, "running", statusVersion)
      statusVersion++
    }

    // 7. Resume batch processing from next batch
    const coordinator = yield* CheckpointCoordinatorService

    for (let batchIndex = startBatchIndex; batchIndex < batches.length; batchIndex++) {
      const batchChunks = batches[batchIndex]

      // Create checkpoint token for coordination
      const checkpointToken = yield* coordinator.createCheckpoint(params.runId, batchIndex)

      // Process batch with current entity cache
      const result = yield* processBatchActivity({
        runId: params.runId,
        chunks: batchChunks,
        batchIndex,
        ontology: params.ontology,
        ontologyGraph: params.ontologyGraph,
        ontologyHash: parseInt(run.ontology_hash, 16), // Convert hex back to number
        initialEntitySnapshot: batchIndex === 0 ? undefined : entityCache
      })

      // Save batch + checkpoint atomically
      const _saveResult = yield* saveBatchWithCheckpointActivity({
        runId: params.runId,
        batchIndex,
        turtleRdf: result.rdf,
        entityCache: result.entities
      }).pipe(
        // Complete checkpoint on success
        Effect.tap((paths) =>
          coordinator.completeCheckpoint(checkpointToken, {
            batchPath: paths.batchResult.path,
            checkpointPath: paths.checkpointResult.path,
            batchHash: paths.batchResult.hexHash,
            checkpointHash: paths.checkpointResult.hexHash
          })
        ),
        // Fail checkpoint on error
        Effect.tapError((error) => coordinator.failCheckpoint(checkpointToken, error))
      )

      // Wait for checkpoint completion before proceeding
      yield* coordinator.awaitCheckpoint(checkpointToken)

      // Update entity cache for next batch
      entityCache = result.entities

      // Update progress ONLY after checkpoint confirmed
      yield* runService.updateProgress(params.runId, batchIndex + 1, batches.length)
    }

    // 8. Merge all batches
    const mergedRdf = yield* mergeAllBatchesActivity({ runId: params.runId })

    // 9. Save final artifact (this also marks run complete)
    yield* saveFinalArtifactActivity({
      runId: params.runId,
      mergedTurtle: mergedRdf
    })

    return { runId: params.runId, status: "completed" as const }
  }).pipe(
    Effect.catchAll((error) =>
      // Handle ALL errors - mark run as failed
      Effect.gen(function*() {
        const runService = yield* RunService

        yield* runService.markFailed(params.runId, String(error))

        return {
          runId: params.runId,
          status: "failed" as const,
          error: String(error)
        }
      })
    )
  )
